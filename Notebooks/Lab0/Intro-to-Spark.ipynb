{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Lab Number : 0\n",
    "\n",
    "## Title : *Introduction to Spark* \n",
    "\n",
    "## Goal : Spark basics. Getting famililar with Datasets / RDDs / Transformations and Actions  \n",
    "\n",
    "## In this Lab we will cover the:\n",
    "\n",
    "\n",
    "1. Spark Datasets and RDDs \n",
    "2. Datasets Transformations and actions\n",
    "3. Lambda functions\n",
    "4. More on Dataset actions\n",
    "5. More on Dataset transformations\n",
    "6. Lazy Evaluation \n",
    "\n",
    "## References:\n",
    "\n",
    "1. Spark API reference : https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD\n",
    "\n",
    "## Dataset reference:\n",
    "\n",
    "https://grouplens.org/datasets/movielens/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSession and SparkContext objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Lab0\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f855018b0f0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is it?\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is SparkContext also available?\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:  \n",
    "Inspect the Spar UI Link (open link in a new tab) to get familiar with the Spark User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Spark RDDs and Datasets Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#\n",
    "# If you need to read some environment var  e.g. HOME : \n",
    "# os.environ.get('HOME')\n",
    "#\n",
    "datasets_path='/spark-course/data/'\n",
    "movies = datasets_path+'movies/ml-latest-small/movies.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an RDD by using the SparkContext object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/spark-course/data/movies/ml-latest-small/movies.csv MapPartitionsRDD[45] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a  Dataframe (Dataset[Row]) by using the SparkSession object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RDDs transformations and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId,title,genres',\n",
       " '1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
       " '2,Jumanji (1995),Adventure|Children|Fantasy',\n",
       " '3,Grumpier Old Men (1995),Comedy|Romance',\n",
       " '4,Waiting to Exhale (1995),Comedy|Drama|Romance']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check contents of first 5 lines using the RDD\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check contents of first 5 lines using the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='movieId,title,genres'),\n",
       " Row(value='1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(value='2,Jumanji (1995),Adventure|Children|Fantasy'),\n",
       " Row(value='3,Grumpier Old Men (1995),Comedy|Romance'),\n",
       " Row(value='4,Waiting to Exhale (1995),Comedy|Drama|Romance')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9126"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many lines we have - perform an action\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9126"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a dataset of (Int, String, String) tuples.\n",
    "# each entry (row) correspond to : movieId , title , genres\n",
    "\n",
    "# Explained : \n",
    "# 1. Use a transformation (map) to split the data wherever it finds a comma.\n",
    "# 2. Use a transformation (map) to assign each of these results onto a python list for each row\n",
    "tuples_rdd = rdd \\\n",
    "            .map(lambda line: line.split(\",\")) \\\n",
    "            .map(lambda row: [row[0],row[1],row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[65] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movieId', 'title', 'genres'],\n",
       " ['1', 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy'],\n",
       " ['2', 'Jumanji (1995)', 'Adventure|Children|Fantasy'],\n",
       " ['3', 'Grumpier Old Men (1995)', 'Comedy|Romance'],\n",
       " ['4', 'Waiting to Exhale (1995)', 'Comedy|Drama|Romance']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now some dive into the data: (chaining transformations and action)\n",
    "#\n",
    "# 1. count how many Comedy cataloged movies are there in this dataset\n",
    "#    we perform a transformation (filter) followed by an action count()\n",
    "#\n",
    "comedy=tuples_rdd.filter(lambda row : 'Comedy'   in row[2]).count()\n",
    "drama=tuples_rdd.filter(lambda row : 'Drama'    in row[2]).count()\n",
    "romac=tuples_rdd.filter(lambda row : 'Romance'  in row[2]).count()\n",
    "child=tuples_rdd.filter(lambda row : 'Children' in row[2]).count()\n",
    "scifi=tuples_rdd.filter(lambda row : 'Sci'      in row[2]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comedies :-) 2611 0.3 \n",
      "dramas   :-( 3264 0.4 \n",
      "scifi    X-J 656 0.1 \n"
     ]
    }
   ],
   "source": [
    "print('comedies :-) %-d %.1f ' %(comedy,comedy/rdd.count()))\n",
    "print('dramas   :-( %-d %.1f ' %(drama ,drama/rdd.count()))\n",
    "print('scifi    X-J %-d %.1f ' %(scifi ,scifi/rdd.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(2) PythonRDD[36] at RDD at PythonRDD.scala:48 []\\n |  /home/asier/spark-course/data/movies/ml-latest-small/movies.csv MapPartitionsRDD[27] at textFile at NativeMethodAccessorImpl.java:0 []\\n |  /home/asier/spark-course/data/movies/ml-latest-small/movies.csv HadoopRDD[26] at textFile at NativeMethodAccessorImpl.java:0 []'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the DAG\n",
    "tuples.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_data=datasets_path+'bank.csv'\n",
    "# Use it to load some data\n",
    "df= spark \\\n",
    "    .read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(bank_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\": string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is df ?\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok , but this is not very ... telling , we want to see some of the data also\n",
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- \"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\": string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can se how a Spark DataFrame is actually a Dataset[Row] abstraction\n",
    "# Let's analyze some data\n",
    "# First let's check the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but there seems to be something odd here there is only the 'root' node and then a flat leaf \n",
    "# with everything recorded as strings , even stuff that is certainly numeric\n",
    "# so .. let's provide ourselves the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually specifying data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can specify the schema ourselves\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "fields = [ \\\n",
    "          StructField(\"age\", DoubleType(), True), \\\n",
    "          StructField(\"job\", StringType(), True), \\\n",
    "          StructField(\"marital\", StringType(), True), \\\n",
    "          StructField(\"education\", StringType(), True), \\\n",
    "          StructField(\"default\", StringType(), True), \\\n",
    "          StructField(\"balance\", DoubleType(), True), \\\n",
    "          StructField(\"housing\", StringType(), True), \\\n",
    "          StructField(\"loan\", StringType(), True), \\\n",
    "          StructField(\"contact\", StringType(), True), \\\n",
    "          StructField(\"day\", StringType(), True), \\\n",
    "          StructField(\"month\", StringType(), True), \\\n",
    "          StructField(\"duration\", IntegerType(), True), \\\n",
    "          StructField(\"campaign\", IntegerType(), True), \\\n",
    "          StructField(\"pdays\", IntegerType(), True), \\\n",
    "          StructField(\"previous\", IntegerType(), True), \\\n",
    "          StructField(\"poutcome\", StringType(), True)]\n",
    "\n",
    "custom_schema=StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdf= spark \\\n",
    "    .read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .schema(custom_schema) \\\n",
    "    .csv(bank_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Inferring the schema ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
