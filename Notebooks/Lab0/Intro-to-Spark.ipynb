{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab Number : 0\n",
    "\n",
    "### Title : *Introduction to Spark* \n",
    "\n",
    "### Goal : Spark basics. Getting famililar with Datasets / RDDs / Transformations and Actions  \n",
    "\n",
    "### In this Lab we will cover the:\n",
    "\n",
    "\n",
    "1. Spark Datasets and RDDs \n",
    "3. Datasets Transformations and actions\n",
    "2. Lambda functions\n",
    "3. More on Dataset actions\n",
    "4. More on Dataset transformations\n",
    "5. Lazy Evaluation \n",
    "\n",
    "### References:\n",
    "\n",
    "1. Spark API reference : https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD\n",
    "\n",
    "### Dataset reference:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtual Environments\n",
    "\n",
    "Python virtual environments are a very useful feature that allows the creation of a controlled (and contained) working environment with tailored package installations for each analysis scenario.\n",
    "Think about it!\n",
    "For example : if you needed to use different python versions , you can create specific environments for each version\n",
    "How : \n",
    "% conda-create env -n <name>\n",
    "% source activate <name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%python3` not found (But cell magic `%%python3` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "# %python3 -m venv course-env python=3.6\n",
    "# %source activate course-env "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a SparkSession object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Lab0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.34:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f915a453710>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is it?\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:  Inspect the Spar UI Link (above) to get familiar with the Spark architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Spark Datasets and RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "datasets_path= os.environ.get('HOME')+'/spark-course/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset reference : https://grouplens.org/datasets/movielens/\n",
    "movies = datasets_path+'movies/ml-latest-small/movies.csv'\n",
    "# Create an RDD called lines\n",
    "lines = sc.textFile(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/asier/spark-course/data/movies/ml-latest-small/movies.csv MapPartitionsRDD[71] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is lines ?\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9126"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many lines we have - perform an action\n",
    "lines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId,title,genres',\n",
       " '1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
       " '2,Jumanji (1995),Adventure|Children|Fantasy',\n",
       " '3,Grumpier Old Men (1995),Comedy|Romance',\n",
       " '4,Waiting to Exhale (1995),Comedy|Drama|Romance']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check contents of first 5 lines\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. RDDs transformations and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataset of (Int, String, String) tuples.\n",
    "# each entry (row) correspond to : movieId , title , genres\n",
    "\n",
    "# Explained : \n",
    "# 1. Use a transformation (map) to split the data wherever it finds a comma.\n",
    "# 2. Use a transformation (map) to assign each of these results onto a python list for each row\n",
    "tuples = lines.map(lambda line: line.split(\",\")) \\\n",
    "             .map(lambda row: [row[0],row[1],row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[74] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movieId', 'title', 'genres'],\n",
       " ['1', 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy'],\n",
       " ['2', 'Jumanji (1995)', 'Adventure|Children|Fantasy'],\n",
       " ['3', 'Grumpier Old Men (1995)', 'Comedy|Romance'],\n",
       " ['4', 'Waiting to Exhale (1995)', 'Comedy|Drama|Romance']]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many Comedy cataloged movies are there in this dataset\n",
    "# We perform a transformation (filter) followed by an action count()\n",
    "comedy=tuples.filter(lambda r : 'Comedy' in r[2]).count()\n",
    "drama=tuples.filter(lambda r : 'Drama' in r[2]).count()\n",
    "romac=tuples.filter(lambda r : 'Romance' in r[2]).count()\n",
    "child=tuples.filter(lambda r : 'Children' in r[2]).count()\n",
    "scifi=tuples.filter(lambda r : 'Sci' in r[2]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comedies :-) 2611 0.3 \n",
      "dramas   :-( 3264 0.4 \n",
      "scifi    X-J 656 0.1 \n"
     ]
    }
   ],
   "source": [
    "print('comedies :-) %d %.1f ' %(comedy,comedy/lines.count()))\n",
    "print('dramas   :-( %d %.1f ' %(drama ,drama/lines.count()))\n",
    "print('scifi    X-J %d %.1f ' %(scifi ,scifi/lines.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(2) PythonRDD[36] at RDD at PythonRDD.scala:48 []\\n |  /home/asier/spark-course/data/movies/ml-latest-small/movies.csv MapPartitionsRDD[27] at textFile at NativeMethodAccessorImpl.java:0 []\\n |  /home/asier/spark-course/data/movies/ml-latest-small/movies.csv HadoopRDD[26] at textFile at NativeMethodAccessorImpl.java:0 []'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the DAG\n",
    "tuples.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_data=datasets_path+'bank.csv'\n",
    "# Use it to load some data\n",
    "df= spark \\\n",
    "    .read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(bank_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\": string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is df ?\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"'),\n",
       " Row(\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\"='59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok , but this is not very ... telling , we want to see some of the data also\n",
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- \"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\": string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can se how a Spark DataFrame is actually a Dataset[Row] abstraction\n",
    "# Let's analyze some data\n",
    "# First let's check the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but there seems to be something odd here there is only the 'root' node and then a flat leaf \n",
    "# with everything recorded as strings , even stuff that is certainly numeric\n",
    "# so .. let's provide ourselves the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually specifying data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can specify the schema ourselves\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "fields = [ \\\n",
    "          StructField(\"age\", DoubleType(), True), \\\n",
    "          StructField(\"job\", StringType(), True), \\\n",
    "          StructField(\"marital\", StringType(), True), \\\n",
    "          StructField(\"education\", StringType(), True), \\\n",
    "          StructField(\"default\", StringType(), True), \\\n",
    "          StructField(\"balance\", DoubleType(), True), \\\n",
    "          StructField(\"housing\", StringType(), True), \\\n",
    "          StructField(\"loan\", StringType(), True), \\\n",
    "          StructField(\"contact\", StringType(), True), \\\n",
    "          StructField(\"day\", StringType(), True), \\\n",
    "          StructField(\"month\", StringType(), True), \\\n",
    "          StructField(\"duration\", IntegerType(), True), \\\n",
    "          StructField(\"campaign\", IntegerType(), True), \\\n",
    "          StructField(\"pdays\", IntegerType(), True), \\\n",
    "          StructField(\"previous\", IntegerType(), True), \\\n",
    "          StructField(\"poutcome\", StringType(), True)]\n",
    "\n",
    "custom_schema=StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdf= spark \\\n",
    "    .read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .schema(custom_schema) \\\n",
    "    .csv(bank_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Inferring the schema ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
